{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install ktrain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## All imports"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nimport os\nfrom torch.utils.data import TensorDataset, DataLoader\nimport re\nimport string\nimport transformers\nimport torch.optim as optim\nfrom tqdm.autonotebook import tqdm\nfrom sklearn.metrics import f1_score,precision_score,recall_score\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/tweet-sentiment-extraction/train.csv\").dropna().reset_index(drop=True)\ntest=pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\").dropna().reset_index(drop=True)\nsample=pd.read_csv(\"../input/tweet-sentiment-extraction/sample_submission.csv\").dropna().reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sentiment Classification using BERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data path is .csv file with 2 columns, having name 'text', 'sentiment'.\n# test is also .csv file with 1 column, name 'text' only\nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\nos.environ[\"VISIBLE_DEVICES\"]=\"0\"\nimport ktrain\nfrom ktrain import text\nDATA_PATH = '../input/tweet-sentiment-extraction/train.csv'\nNUM_WORDS = 25000\nMAXLEN = 128\n(x_train, y_train), (x_test, y_test), preproc = text.texts_from_csv(DATA_PATH,\n                      'text',\n                      label_columns = [\"sentiment\"],\n                      val_filepath='../input/tweet-sentiment-extraction/test.csv', # if None, 10% of data will be used for validation\n                      max_features=NUM_WORDS, maxlen=MAXLEN,\n                      ngram_range=1,preprocess_mode='bert')\nmodel=text.text_classifier('bert',(x_train,y_train),preproc=preproc)\nlearner=ktrain.get_learner(model,(x_train,y_train),(x_test,y_test),batch_size=32)\nlearner.fit(3e-5,3,cycle_len=1,cycle_mult=1)\n# learner.lr_find(max_epochs=3)\n# learner.lr_plot()\npredictor=ktrain.get_predictor(learner.model, preproc)\noutput=predictor.predict(np.array(test['text']))\ncount=0;\nfor i,samp in enumerate(output):\n    if samp==test['sentiment'].iloc[i]:\n        count+=1\nprint(f'accuracy on test data: {count/len(test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sentiment Classification using Distil BERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=train['text'].values\nx_test=test['text'].values\ny_train=train['sentiment'].values\ny_test=test['sentiment'].values\ntrn, val, preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n                                          x_test=x_test, y_test=y_test,\n                                          class_names=[0,1,2],\n                                          preprocess_mode='distilbert',\n                                          maxlen=150)\ntext.print_text_classifiers()\nmodel = text.text_classifier('distilbert', train_data=trn, preproc=preproc)\nlearner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=6)\nlearner.fit_onecycle(3e-5, 4)\np = ktrain.get_predictor(model, preproc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p.predict(val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1macro=f1_score(output,test['sentiment'],average='macro')\nf1avg=f1_score(output,test['sentiment'],average='weighted')\nrecall=recall_score(output,test['sentiment'],average='macro')\nrecallw=recall_score(output,test['sentiment'],average='weighted')\nprecision=precision_score(output,test['sentiment'],average='macro')\nprecisionw=precision_score(output,test['sentiment'],average='weighted')\nprint(f'f1macro: {f1macro} recall: {recall} precision :{precision}')\nprint(\"below result for average\")\nprint(f'f1avg: {f1avg} recall: {recallw} precision :{precisionw}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean(text):\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\d', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Q&A model supervised"},{"metadata":{"trusted":true},"cell_type":"code","source":"class QAModel(nn.Module):\n    \n    def __init__(self):\n        super(QAModel,self).__init__()\n        self.bert=transformers.BertModel.from_pretrained(\"../input/bert-base-uncased\",output_hidden_states=True)\n        self.dropout=nn.Dropout(0.2)\n        self.layer1=nn.Linear(768*2,2)\n        self.softmax=nn.Softmax()\n    \n    def forward(self, ids,attn,token_type):\n        out,_,_=self.bert(ids,attention_mask=attn,token_type_ids=token_type)\n        out=self.dropout(out)\n        out=self.layer1(out)\n        start_logits, end_logits = out.split(1, dim=-1)\n        start_logits = start_logits.squeeze(-1)\n        end_logits = end_logits.squeeze(-1)\n        start=self.softmax(start_logits)\n        end=self.softmax(end_logits)\n        return start_logits,end_logits\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchsummary import summary\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel1=QAModel().to(device)\nprint(model1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* negative: 4997\n* positive: 3893\n* neutral:  8699\n* [CLS]   : 101\n* [SEP]   : 102"},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing\ntoken_ids, attn_masks, token_type_ids, start & end logits"},{"metadata":{"trusted":true},"cell_type":"code","source":"token_ids=[]\nattn_masks=[]\ntoken_type_ids=[]\nstart_logits=[]\nend_logits=[]\ndef preprocess(data,typ):\n    \n    maxlen=115\n    tokenizer=transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n    \n    for i,_ in enumerate(range(len(data))):\n        \n        #finding start & end logits\n        out1=tokenizer.encode_plus(data['text'].iloc[i])\n        if typ=='train':\n            out2=tokenizer.encode_plus(data['selected_text'].iloc[i])\n            l=len(out2['input_ids'])\n        if typ=='train':\n            for i,_ in enumerate(out1['input_ids']):\n                if out1['input_ids'][i:i+l-2]==out2['input_ids'][1:-1]:\n                    break\n            start=i\n            end=i+l-2\n            temp=[0]*(maxlen+2)\n            temp[start]=1\n            start_logits.append(temp)\n            temp=[0]*(maxlen+2)\n            temp[end-1]=1\n            end_logits.append(temp)\n        #making length to maximum\n        if data['sentiment'].iloc[i]=='positive':\n            sentiment_id=4893\n        elif data['sentiment'].iloc[i]=='negative':\n            sentiment_id=4893\n        else:\n            sentiment_id=4893\n        tkn_len=len(out1['input_ids'])\n        out1['input_ids']=[101]+[sentiment_id]+[102]+out1['input_ids'][1:]+(maxlen-tkn_len)*[0]\n        token_ids.append(out1['input_ids'])\n        \n        token_type_ids.append(3*[1]+out1['token_type_ids']+(maxlen-tkn_len-1)*[1])\n        attn_masks.append(2*[1]+out1['attention_mask']+(maxlen-tkn_len)*[0])\n    if typ=='train':\n        data['start']=start_logits\n        data['end']=end_logits\n    data['token_ids']=token_ids\n    data['token_type']=token_type_ids\n    data['attn_masks']=attn_masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess(train,'train')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Loader"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Loader:\n    def __init__(self,data):\n        self.data=data\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        data= {\n                'ids':torch.tensor(self.data['token_ids'].iloc[idx],dtype=torch.long),\n                'token_type_ids':torch.tensor(self.data['token_type'].iloc[idx],dtype=torch.long),\n                'attn_masks':torch.tensor(self.data['attn_masks'].iloc[idx],dtype=torch.long),\n                'start':torch.tensor(self.data['start'].iloc[idx],dtype=torch.float),\n                'end':torch.tensor(self.data['end'].iloc[idx],dtype=torch.float)\n        }\n        return data\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking gpu"},{"metadata":{"trusted":true},"cell_type":"code","source":"if torch.cuda.is_available():\n    device='cuda'\nelse:\n    device='cpu'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_fn(start_logits,end_logits,start_pos,end_pos):\n    f=nn.CrossEntropyLoss()\n    loss1=f(start_logits,torch.argmax(start_pos,dim=-1))\n    loss2=f(end_logits,torch.argmax(end_pos,dim=-1))\n    return loss1+loss2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def training(model,train_data,device,optimizer):\n    total_loss=0\n    model.train()\n    train_data=tqdm(train_data,total=len(train_data))\n    for i,train_data1 in enumerate(train_data):\n        optimizer.zero_grad()\n        start,end=model(train_data1['ids'].to(device),train_data1['attn_masks'].to(device),train_data1['token_type_ids'].to(device))\n        loss_=loss_fn(start,end,train_data1['start'].to(device),train_data1['end'].to(device))\n        loss_.backward()\n        optimizer.step()\n        total_loss+=loss_.item()\n    return total_loss\n\ndef evaluation(model,eval_data,device,optimizer):\n    model.eval()\n    start_logits=[]\n    end_logits=[]\n    total_loss=0\n    with torch.no_grad():\n        for eval_data1 in eval_data:\n            optimizer.zero_grad()\n            start,end=model(eval_data1['ids'].to(device),eval_data1['attn_masks'].to(device),\n                            eval_data1['token_type_ids'].to(device))\n#             loss_=loss(start,end,eval_data1['start'].to(device),\n#                        eval_data1['end'].to(device))\n#             total_loss+=loss_.item()\n            \n            start=(start.cpu().detach().numpy())\n            end=(end.cpu().detach().numpy())\n            start=np.argmax(start,axis=-1)\n            end=np.argmax(end,axis=-1)\n            start_logits.append(start)\n            end_logits.append(end)\n    return total_loss,start_logits,end_logits,eval_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train,test=train_test_split(train,test_size=0.2)\ntrain_data=Loader(train)\ntest_data=Loader(test)\ntrain_data=torch.utils.data.DataLoader(train_data,batch_size=16,shuffle=True)\ntest_data=torch.utils.data.DataLoader(test_data,batch_size=16,shuffle=False)\nepochs=10\nmodel=QAModel()\nmodel.to(device)\noptimizer=optim.Adam(model.parameters(),lr=1e-5)\nfor _ in range(epochs):\n    loss=training(model,train_data,device,optimizer)\n    print(loss)\ntorch.save(model.state_dict(),'bertmodel.pkl')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluating function"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=QAModel()\nmodel.state_dict(torch.load('./bertmodel.pkl'))\nmodel.to(device)\npreprocess(test,'test')\ntest_data=Loader(test)\ntest_data=torch.utils.data.DataLoader(test_data,batch_size=16,shuffle=False)\nloss,start_idx,end_idx,data=evaluation(model,test_data,device,optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start=np.concatenate(start_idx)\nend=np.concatenate(end_idx)\ncount=0\nfor i in range(len(start)):\n    if(start[i]>end[i]):\n        count+=1\ncount","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selecting the extracted text"},{"metadata":{"trusted":true},"cell_type":"code","source":"selec_text=[]\ndef result(start,end):\n    score=0\n    for i in range(len(start)):\n        if start[i]>=end[i]:\n            selec_text.append(test['text'].iloc[i])\n        else:\n            selec_text.append(test['text'].iloc[i][start[i]:end[i]])\nresult(start,end)            \nsample['selected_text']=selec_text\nsample.to_csv('sample_submission.csv',header=None,index=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## jaccard score"},{"metadata":{"trusted":true},"cell_type":"code","source":"score=0\nfor i in range(len(selec_text)):\n    a=text['selected_text'].iloc[i].split()\n    b=selec_text[i].split()\n    numer=len(len(set(a).intersection(b)))\n    denom=len(len(set(a).union(b)))\n    score+=numer/denom\nscore=score/len(test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}